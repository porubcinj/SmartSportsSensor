{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "yT8UGbqhxwgs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rlOledmZw1cs"
      },
      "outputs": [],
      "source": [
        "def load_samples_and_labels(\n",
        "    csv_path: str,\n",
        "    window_size: int = 64,\n",
        "    feature_cols: list[str] | None = None,\n",
        "    label_col: str = \"label\"\n",
        ") -> tuple[np.ndarray, np.ndarray]:\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # pick feature columns\n",
        "    if feature_cols is None:\n",
        "        feature_cols = [c for c in df.columns if c != label_col]\n",
        "\n",
        "    # pull out raw arrays\n",
        "    data   = df[feature_cols].to_numpy(dtype=np.float32)\n",
        "    labels = df[label_col].to_numpy()            # e.g. int32 or string\n",
        "\n",
        "    # how many full windows fit?\n",
        "    n_windows = data.shape[0] // window_size\n",
        "    data   = data[:n_windows * window_size]\n",
        "    labels = labels[:n_windows * window_size]\n",
        "\n",
        "    # reshape\n",
        "    X = data.reshape(n_windows, window_size, len(feature_cols))\n",
        "    L = labels.reshape(n_windows, window_size)\n",
        "\n",
        "    # now pick one label per window (e.g. the first, or majority)\n",
        "    # here we assume they're all the same, so we take the first:\n",
        "    y = L[:, 0]\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cols = [\"ax'\", \"ay'\", \"az'\", \"gx'\", \"gy'\", \"gz'\"]\n",
        "label_col = \"stroke_side_spin\"\n",
        "folder_path = \"./stroke_peaks\""
      ],
      "metadata": {
        "collapsed": true,
        "id": "1n7trjFZyunH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = []\n",
        "\n",
        "all_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
        "\n",
        "for filename in all_files:\n",
        "\n",
        "    X, y = load_samples_and_labels(filename, window_size=64, feature_cols=feature_cols, label_col=label_col)\n",
        "    print(filename, X.shape, y.shape)  # -> (n_samples, 64, n_features), (n_samples,)\n",
        "\n",
        "    all_data.append((X, y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hNDAD0JdzgBp",
        "outputId": "4a1baa98-df6a-4e73-83ef-ba607663fc13"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./stroke_peaks/serve_forehand_flat.csv (53, 64, 6) (53,)\n",
            "./stroke_peaks/overhead_forehand_flat.csv (46, 64, 6) (46,)\n",
            "./stroke_peaks/groundstroke_forehand_flat.csv (37, 64, 6) (37,)\n",
            "./stroke_peaks/groundstroke_forehand_slice.csv (77, 64, 6) (77,)\n",
            "./stroke_peaks/volley_backhand_slice.csv (89, 64, 6) (89,)\n",
            "./stroke_peaks/groundstroke_backhand_slice.csv (55, 64, 6) (55,)\n",
            "./stroke_peaks/serve_forehand_slice.csv (38, 64, 6) (38,)\n",
            "./stroke_peaks/groundstroke_backhand_flat.csv (44, 64, 6) (44,)\n",
            "./stroke_peaks/overhead_forehand_slice.csv (36, 64, 6) (36,)\n",
            "./stroke_peaks/volley_forehand_slice.csv (70, 64, 6) (70,)\n",
            "./stroke_peaks/serve_forehand_topspin.csv (58, 64, 6) (58,)\n",
            "./stroke_peaks/groundstroke_backhand_topspin.csv (36, 64, 6) (36,)\n",
            "./stroke_peaks/groundstroke_forehand_topspin.csv (19, 64, 6) (19,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.concatenate([X for X, y in all_data], axis=0)\n",
        "y = np.concatenate([y for X, y in all_data], axis=0)\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "np.savez('stroke_peak_data.npz', X=X, y=y)"
      ],
      "metadata": {
        "id": "ToHXFs478_zJ"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}