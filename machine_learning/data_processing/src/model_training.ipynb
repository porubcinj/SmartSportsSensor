{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "Ls6P2rbXzybz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential, Input\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv1D, BatchNormalization, Activation,\n",
        "    MaxPooling1D, Dropout, Flatten, Dense\n",
        ")\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "5Nd3uE1g0itR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dG463iQXMf9",
        "outputId": "8d8ddf5a-63d8-4429-9ae4-04a7fe4e0c02"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGSvswHMzgTV",
        "outputId": "e74ca9af-a10d-49e5-e7ca-7e585462a896"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 658, each window shape: (64, 6)\n",
            "Labels shape: (658,)\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "data = np.load('stroke_peak_data.npz')\n",
        "X = data['X']\n",
        "y = data['y']\n",
        "\n",
        "print(f\"Total samples: {X.shape[0]}, each window shape: {X.shape[1:]}\")\n",
        "print(f\"Labels shape: {y.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train, validation, and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "num_classes = len(set(y_train))\n",
        "\n",
        "print(\"After split:\")\n",
        "print(f\"  X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "print(f\"  X_test : {X_test.shape},  y_test : {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJKhnCOHzyGe",
        "outputId": "b3c3b58c-3206-4db0-aed7-61f4e991cdfd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After split:\n",
            "  X_train: (526, 64, 6), y_train: (526,)\n",
            "  X_test : (132, 64, 6),  y_test : (132,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conv1D Model\n",
        "def build_model():\n",
        "    model = Sequential([\n",
        "        Input(shape=(64, 6)),\n",
        "\n",
        "        Conv1D(64, kernel_size=3, padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Activation('relu'),\n",
        "        Dropout(0.2),\n",
        "\n",
        "        Conv1D(128, kernel_size=3, padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Activation('relu'),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.2),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.4),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.4),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "#model.summary()"
      ],
      "metadata": {
        "id": "QvEWX-Wb05Oj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "val_accuracies = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train)):\n",
        "    print(f\"\\n--- Fold {fold+1} ---\")\n",
        "    X_tr, X_va = X_train[train_idx], X_train[val_idx]\n",
        "    y_tr, y_va = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "    # 4. Build a fresh model and callbacks for each fold\n",
        "    model = build_model()\n",
        "    early = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
        "\n",
        "    # 5. Train\n",
        "    history = model.fit(\n",
        "        X_tr, y_tr,\n",
        "        validation_data=(X_va, y_va),\n",
        "        epochs=256,\n",
        "        batch_size=16,\n",
        "        callbacks=[early],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # 6. Evaluate on this fold’s validation set\n",
        "    val_loss, val_acc = model.evaluate(X_va, y_va, verbose=0)\n",
        "    print(f\"Fold {fold+1} val accuracy: {val_acc:.4f}\")\n",
        "    val_accuracies.append(val_acc)\n",
        "\n",
        "# 7. Aggregate results\n",
        "val_accuracies = np.array(val_accuracies)\n",
        "print(f\"\\nMean val accuracy: {val_accuracies.mean():.4f} ± {val_accuracies.std():.4f}\")\n",
        "\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpB_z4tPSGqq",
        "outputId": "e1a1c90c-006b-4d0d-cebe-d97d2d075663"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Fold 1 ---\n",
            "Fold 1 val accuracy: 0.6792\n",
            "\n",
            "--- Fold 2 ---\n",
            "Fold 2 val accuracy: 0.6286\n",
            "\n",
            "--- Fold 3 ---\n",
            "Fold 3 val accuracy: 0.6476\n",
            "\n",
            "--- Fold 4 ---\n",
            "Fold 4 val accuracy: 0.6667\n",
            "\n",
            "--- Fold 5 ---\n",
            "Fold 5 val accuracy: 0.6286\n",
            "\n",
            "Mean val accuracy: 0.6501 ± 0.0203\n",
            "Test accuracy: 0.591\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "early = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=256,\n",
        "    batch_size=16,\n",
        "    callbacks=[early]\n",
        ")\n",
        "\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhbP3J401Hd2",
        "outputId": "6085ab26-e93c-49e6-e648-d49080776038"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.1263 - loss: 2.6427 - val_accuracy: 0.1288 - val_loss: 2.4839\n",
            "Epoch 2/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.4307 - loss: 1.7071 - val_accuracy: 0.1742 - val_loss: 2.4842\n",
            "Epoch 3/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6103 - loss: 1.1864 - val_accuracy: 0.2955 - val_loss: 2.0941\n",
            "Epoch 4/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7686 - loss: 0.7752 - val_accuracy: 0.3864 - val_loss: 1.7910\n",
            "Epoch 5/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8515 - loss: 0.4707 - val_accuracy: 0.4015 - val_loss: 1.6998\n",
            "Epoch 6/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9624 - loss: 0.2479 - val_accuracy: 0.4394 - val_loss: 1.7198\n",
            "Epoch 7/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9662 - loss: 0.1914 - val_accuracy: 0.4773 - val_loss: 1.5890\n",
            "Epoch 8/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9789 - loss: 0.1323 - val_accuracy: 0.5152 - val_loss: 1.6514\n",
            "Epoch 9/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9911 - loss: 0.0651 - val_accuracy: 0.4848 - val_loss: 1.6394\n",
            "Epoch 10/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9852 - loss: 0.0696 - val_accuracy: 0.5076 - val_loss: 1.7483\n",
            "Epoch 11/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0271 - val_accuracy: 0.5076 - val_loss: 1.8467\n",
            "Epoch 12/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0185 - val_accuracy: 0.5379 - val_loss: 1.7759\n",
            "Epoch 13/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.5227 - val_loss: 1.8552\n",
            "Epoch 14/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0085 - val_accuracy: 0.5455 - val_loss: 1.9027\n",
            "Epoch 15/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.5303 - val_loss: 1.8847\n",
            "Epoch 16/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.5682 - val_loss: 1.9141\n",
            "Epoch 17/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.5530 - val_loss: 1.9262\n",
            "Epoch 18/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.5530 - val_loss: 2.0545\n",
            "Epoch 19/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.5076 - val_loss: 2.0112\n",
            "Epoch 20/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.5303 - val_loss: 2.0006\n",
            "Epoch 21/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.5379 - val_loss: 2.0525\n",
            "Epoch 22/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.5455 - val_loss: 2.0158\n",
            "Epoch 23/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.5530 - val_loss: 2.0155\n",
            "Epoch 24/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.5227 - val_loss: 2.0764\n",
            "Epoch 25/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.5152 - val_loss: 2.1472\n",
            "Epoch 26/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.5152 - val_loss: 2.1981\n",
            "Epoch 27/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9951 - loss: 0.0079 - val_accuracy: 0.5530 - val_loss: 2.0699\n",
            "Epoch 28/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.5455 - val_loss: 2.1365\n",
            "Epoch 29/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.5530 - val_loss: 2.0874\n",
            "Epoch 30/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.5530 - val_loss: 2.1441\n",
            "Epoch 31/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.5530 - val_loss: 2.1386\n",
            "Epoch 32/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.5455 - val_loss: 2.1282\n",
            "Epoch 33/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.5530 - val_loss: 2.1362\n",
            "Epoch 34/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.5530 - val_loss: 2.1611\n",
            "Epoch 35/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.5455 - val_loss: 2.1723\n",
            "Epoch 36/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.5758 - val_loss: 2.1741\n",
            "Epoch 37/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 8.2742e-04 - val_accuracy: 0.5530 - val_loss: 2.2037\n",
            "Epoch 38/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.5455 - val_loss: 2.1852\n",
            "Epoch 39/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 9.0978e-04 - val_accuracy: 0.5455 - val_loss: 2.2213\n",
            "Epoch 40/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 7.0648e-04 - val_accuracy: 0.5379 - val_loss: 2.2245\n",
            "Epoch 41/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 6.8621e-04 - val_accuracy: 0.5379 - val_loss: 2.2219\n",
            "Epoch 42/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 6.0738e-04 - val_accuracy: 0.5303 - val_loss: 2.2351\n",
            "Epoch 43/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 7.6144e-04 - val_accuracy: 0.5455 - val_loss: 2.2183\n",
            "Epoch 44/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 6.1346e-04 - val_accuracy: 0.5455 - val_loss: 2.2434\n",
            "Epoch 45/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 6.3413e-04 - val_accuracy: 0.5379 - val_loss: 2.2479\n",
            "Epoch 46/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 6.0378e-04 - val_accuracy: 0.5455 - val_loss: 2.2705\n",
            "Epoch 47/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 6.3371e-04 - val_accuracy: 0.5455 - val_loss: 2.2941\n",
            "Epoch 48/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 6.2644e-04 - val_accuracy: 0.5530 - val_loss: 2.3150\n",
            "Epoch 49/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 7.8084e-04 - val_accuracy: 0.5530 - val_loss: 2.3112\n",
            "Epoch 50/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 5.1700e-04 - val_accuracy: 0.5455 - val_loss: 2.3059\n",
            "Epoch 51/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 6.3280e-04 - val_accuracy: 0.5455 - val_loss: 2.2958\n",
            "Epoch 52/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 3.9658e-04 - val_accuracy: 0.5455 - val_loss: 2.3047\n",
            "Epoch 53/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 3.0398e-04 - val_accuracy: 0.5379 - val_loss: 2.3256\n",
            "Epoch 54/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 4.5582e-04 - val_accuracy: 0.5455 - val_loss: 2.3301\n",
            "Epoch 55/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 4.6008e-04 - val_accuracy: 0.5455 - val_loss: 2.3233\n",
            "Epoch 56/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 3.5048e-04 - val_accuracy: 0.5379 - val_loss: 2.3420\n",
            "Epoch 57/256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 3.6051e-04 - val_accuracy: 0.5530 - val_loss: 2.3363\n",
            "Test accuracy: 0.485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to TFLite\n",
        "def representative_dataset():\n",
        "    for input_value in tf.data.Dataset.from_tensor_slices(X_train).batch(1).take(100):\n",
        "        # ensure dtype matches your input dtype (float32 here)\n",
        "        yield [input_value]\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset\n",
        "\n",
        "# For full integer quantization (weights + activations)\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type  = tf.uint8   # or tf.int8\n",
        "converter.inference_output_type = tf.uint8   # match input type\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "open('conv1d_model.tflite', 'wb').write(tflite_model)\n",
        "print(\"TFLite model written to conv1d_model.tflite\")"
      ],
      "metadata": {
        "id": "zRS3MkKy184R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}